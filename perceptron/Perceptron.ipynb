{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-10T13:37:36.331018Z",
     "start_time": "2025-09-10T13:37:35.513032Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sympy import *\n",
    "\n",
    "def step_function(x):\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        self.classes_ = None # The unique classes labels.\n",
    "        self.coef_ = None # Weights assigned to the features.\n",
    "        self.intercept_= None # Bias vector.\n",
    "        self.n_features_in_= None # Number of features seen during fit.\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Names of features seen during fit. Defined only when X has feature names that are all strings.\n",
    "        self.feature_names_in_= None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.feature_names_in_ = X.columns\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "\n",
    "        # 행 개수: 입력 특성 개수\n",
    "        # 열 개수: TLU 뉴런 개수\n",
    "        # 열 벡터가 가중치 벡터임.\n",
    "        self.coef_ = np.random.rand(self.n_features_in_, len(self.classes_))\n",
    "\n",
    "        # 편향 벡터\n",
    "        self.intercept_ = np.zeros(len(self.classes_))\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(self.coef_.shape[1]):\n",
    "                outputs = step_function(np.dot(X.iloc[i].values, self.coef_[:, j]) + self.intercept_[j])\n",
    "                \n",
    "                # 가중치 업데이트\n",
    "                # 만약 타깃값과 예측값이 동일하다면 가중치는 업데이트되지 않는다.\n",
    "                # 만약 타깃값이 양수인데 예측값은 음수가 나왔다면 (y[i, j] - outputs) 값은 양수가 되어 가중치에 양수를 더하게 됨.\n",
    "                # 타깃값은 음수이고 예측값은 양수라면 그 반대로 가중치에 음수를 더하게 됨.\n",
    "                self.coef_[:, j] += self.learning_rate * X.iloc[i].values * (y[i, j] - outputs)\n",
    "\n",
    "                # 편향 업데이트\n",
    "                self.intercept_[j] += self.learning_rate * (y[i, j] - outputs)\n",
    "                    \n",
    "    def predict(self, X):\n",
    "        # 원래 수학에서는 행렬과 벡터의 덧셈은 정의되지 않음. 하지만 넘파이에서는 기능 제공함.\n",
    "        # 아래와 같이 작성하면 넘파이가 자동으로 행렬의 각 행에 편향 벡터를 더해준다.\n",
    "        z_score = (X @ self.coef_) + self.intercept_\n",
    "\n",
    "        return step_function(z_score) # 활성화(activation) 함수 적용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12512473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Perceptron Accuracy: 0.8566666666666667\n",
      "Sklearn Perceptron Accuracy: 0.9033333333333333\n",
      "\n",
      "User Confusion Matrix:\n",
      " [[120  30]\n",
      " [ 13 137]]\n",
      "\n",
      "Sklearn Confusion Matrix:\n",
      " [[143   7]\n",
      " [ 22 128]]\n",
      "\n",
      "Sklearn Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       150\n",
      "           1       0.95      0.85      0.90       150\n",
      "\n",
      "    accuracy                           0.90       300\n",
      "   macro avg       0.91      0.90      0.90       300\n",
      "weighted avg       0.91      0.90      0.90       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 비교 실험: 사용자 Perceptron vs scikit-learn Perceptron\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron as SkPerceptron\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1) 데이터 생성 (이진 분류)\n",
    "X_np, y_np = make_classification(n_samples=1000, n_features=4, n_informative=3,\n",
    "                                 n_redundant=0, n_classes=2, class_sep=1.0,\n",
    "                                 random_state=42)\n",
    "\n",
    "# 2) DataFrame/Series로 변환 (사용자 Perceptron은 pandas 입력을 기대)\n",
    "feature_names = [f\"x{i}\" for i in range(X_np.shape[1])]\n",
    "X_df = pd.DataFrame(X_np, columns=feature_names)\n",
    "y_sr = pd.Series(y_np, name=\"target\")\n",
    "\n",
    "# 3) train/test 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_sr, test_size=0.3, random_state=42, stratify=y_sr)\n",
    "\n",
    "# 4) 스케일링 (scikit-learn과의 공정 비교를 위해 둘 다 같은 입력 사용)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# 5) 사용자 Perceptron 학습 준비: 원-핫 타깃으로 변환 (사용자 구현은 다중 출력 벡터를 기대)\n",
    "classes = np.sort(y_train.unique())\n",
    "class_to_index = {c: i for i, c in enumerate(classes)}\n",
    "Y_train_onehot = np.zeros((len(y_train), len(classes)))\n",
    "for idx, label in enumerate(y_train.values):\n",
    "    Y_train_onehot[idx, class_to_index[label]] = 1\n",
    "\n",
    "# 6) 사용자 Perceptron 학습\n",
    "usr_clf = Perceptron(learning_rate=0.01)\n",
    "usr_clf.fit(X_train_scaled, Y_train_onehot)\n",
    "\n",
    "# 7) 사용자 Perceptron 예측 함수 (원-핫 출력 가정 -> argmax로 클래스 선택)\n",
    "def predict_user(clf, X):\n",
    "    z = (X.values @ clf.coef_) + clf.intercept_  # (n_samples, n_classes)\n",
    "    # step_function은 스칼라에 정의되어 있음 -> 벡터에 적용하면 브로드캐스팅 이슈 있으므로 여기서 처리\n",
    "    outputs = (z > 0).astype(int)\n",
    "    # 결정은 z 점수의 argmax로 수행 (표준 퍼셉트론의 선형 결정)\n",
    "    preds = np.argmax(z, axis=1)\n",
    "    return preds, outputs\n",
    "\n",
    "usr_pred_labels, usr_raw_outputs = predict_user(usr_clf, X_test_scaled)\n",
    "\n",
    "# 8) scikit-learn Perceptron 학습/예측\n",
    "sk_clf = SkPerceptron(alpha=0.0001, max_iter=1000, random_state=42)\n",
    "sk_clf.fit(X_train_scaled, y_train)\n",
    "sk_pred_labels = sk_clf.predict(X_test_scaled)\n",
    "\n",
    "# 9) 성능 지표 계산\n",
    "usr_acc = accuracy_score(y_test, usr_pred_labels)\n",
    "sk_acc = accuracy_score(y_test, sk_pred_labels)\n",
    "\n",
    "print(\"User Perceptron Accuracy:\", usr_acc)\n",
    "print(\"Sklearn Perceptron Accuracy:\", sk_acc)\n",
    "\n",
    "print(\"\\nUser Confusion Matrix:\\n\", confusion_matrix(y_test, usr_pred_labels))\n",
    "print(\"\\nSklearn Confusion Matrix:\\n\", confusion_matrix(y_test, sk_pred_labels))\n",
    "\n",
    "print(\"\\nSklearn Classification Report:\\n\", classification_report(y_test, sk_pred_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-cpu)",
   "language": "python",
   "name": "tf-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
